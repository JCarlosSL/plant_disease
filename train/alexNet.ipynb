{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":862,"status":"ok","timestamp":1704765600462,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"SkqkVwL68nwn","outputId":"149234fb-6019-46cb-ab92-398fde727549"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jan  9 01:59:54 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19761,"status":"ok","timestamp":1704744470674,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"9u9_rpVGZc4q","outputId":"749028b4-9d1b-4179-ecd2-f5abde184a18"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1704744471098,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"Mx1ZAfNva39P","outputId":"2d4834e8-8cd3-4eb2-9275-1e4a839f2ef0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/proyectos3\n","alexNet.ipynb  efficientNet.ipynb  models    PlantVillage_bgremoved  wandb\n","cnn.ipynb      GoogleNet.ipynb\t   PlantDoc  resNet.ipynb\n"]}],"source":["%cd /content/drive/MyDrive/proyectos3/\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"QCZO4-Wz9Mi5"},"source":["# Cargar Conjunto de Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2PjUn8wbFMF"},"outputs":[],"source":["from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import ConcatDataset\n","\n","\n","train_dir0 = './PlantVillage_bgremoved/train'\n","train_dir1 = './PlantDoc/train/'\n","\n","val_dir0 = './PlantVillage_bgremoved/valid'\n","val_dir1 = './PlantDoc/test/'\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dataset0 = ImageFolder(train_dir0, transform=transform,  is_valid_file=lambda x: x.endswith('.JPG'))\n","train_dataset1 = ImageFolder(train_dir1, transform=transform)\n","\n","val_dataset0 = ImageFolder(val_dir0, transform=transform, is_valid_file=lambda x: x.endswith('.JPG'))\n","val_dataset1 = ImageFolder(val_dir1, transform=transform)\n","\n","train_dataset = ConcatDataset([train_dataset0, train_dataset1])\n","val_dataset = ConcatDataset([val_dataset0, val_dataset1])\n","\n","classes = train_dataset0.classes\n","\n","classes"]},{"cell_type":"markdown","metadata":{"id":"ZugaulR0QBux"},"source":["crear carga de datos para facilitar el acceso a los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rednLcxPyaL"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 32\n","num_workers = 8 # Número de procesos que se utilizarán para cargar datos en paralelo\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSnPPujFQ282"},"outputs":[],"source":["import torch\n","\n","def get_default_device():\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6TcjHtjR0F_"},"outputs":[],"source":["device = get_default_device()\n","\n","train_loader = DeviceDataLoader(train_loader, device)\n","val_loader = DeviceDataLoader(val_loader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6XLy8mIIeSy"},"outputs":[],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWuOy6AJrrnH"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_score, f1_score\n","\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","\n","class ImageClassificationBase(nn.Module):\n","\n","    def training_step(self, batch):\n","        \"calculate loss for a batch of training data\"\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        # nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        \"calculate loss, accuracy, precision and f1 score for a batch of validation data\"\n","        images, labels = batch\n","        out = self(images)                   # Generate prediction\n","        # nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss\n","        loss = F.cross_entropy(out, labels)  # Calculate loss\n","        preds = torch.argmax(out, dim=1)\n","        acc = accuracy(out, labels)          # Calculate accuracy\n","\n","        # calculate precision and f1 score\n","        precision = precision_score(labels.cpu(), preds.cpu(), average='weighted', zero_division=1)\n","        f1 = f1_score(labels.cpu(), preds.cpu(), average='macro')\n","        return {'val_loss': loss.detach(), 'val_accuracy': acc, 'val_precision': precision, 'val_f1': f1}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x[\"val_loss\"] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n","        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n","        epoch_accuracy = torch.stack(batch_accuracy).mean()\n","        return {\"val_loss\": epoch_loss.item(), \"val_accuracy\": epoch_accuracy.item()} # Combine accuracies\n","\n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLTn1g_nsrRn"},"outputs":[],"source":["import torchvision.models as models\n","\n","class AlexNet(ImageClassificationBase):\n","    def __init__(self, num_classes):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            # 1st conv layer\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), #96\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            # 2nd conv layer\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2), #256\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            # 3rd conv layer\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            # 4th conv layer\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1), #384\n","            nn.ReLU(inplace=True),\n","            # 5th conv layer\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            # 1st fc layer\n","            nn.Dropout(),\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            # 2nd fc layer\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            # output layer\n","            nn.Linear(4096, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        # flatten the output of conv layers\n","        x = x.view(x.size(0), 256 * 6 * 6)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBrx9WYxstKo"},"outputs":[],"source":["model = AlexNet(len(classes))\n","model = to_device(model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMuflAwMs0TH"},"outputs":[],"source":["from torchsummary import summary              # for getting the summary of our model\n","\n","# getting summary of the model\n","INPUT_SHAPE = (3, 224, 224)\n","print(summary(model.cuda(), (INPUT_SHAPE)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z270ebzHs1Gf"},"outputs":[],"source":["epochs = 20\n","\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayepRCIt_yZL"},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7oieSf5s5LY"},"outputs":[],"source":["#import wandb\n","\n","name = f'alexnet-{epochs}-epochs'\n","wandb.init(project=\"plantvillage-aug\", name=name, config={\n","    \"epochs\": epochs,\n","    \"learning_rate\": max_lr,\n","    \"grad_clip\": grad_clip,\n","    \"weight_decay\": weight_decay,\n","    \"opt_func\": opt_func.__name__,\n","    \"batch_size\": batch_size,\n","    \"dataset\": \"PlantVillage\",\n","    \"architecture\": \"AlexNet\"\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtS2oLwuuAx5"},"outputs":[],"source":["# for training\n","@torch.no_grad()\n","def evaluate(model, val_loader):\n","    \"\"\"Evaluates the model's performance on the validation set\"\"\"\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    # return model.validation_epoch_end(outputs)\n","    val_losses = [x[\"val_loss\"] for x in outputs]\n","    epoch_loss = torch.stack(val_losses).mean()       # Combine loss\n","    val_accuracies = [x[\"val_accuracy\"] for x in outputs]\n","    epoch_accuracy = torch.stack(val_accuracies).mean()\n","    val_precisions = [x[\"val_precision\"] for x in outputs]\n","    epoch_precision = torch.tensor(sum(val_precisions)/len(val_precisions))\n","    val_f1s = [x[\"val_f1\"] for x in outputs]\n","    epoch_f1 = torch.tensor(sum(val_f1s)/len(val_f1s))\n","    return {\"val_loss\": epoch_loss.item(), \"val_accuracy\": epoch_accuracy.item(), \"val_precision\": epoch_precision.item(), \"val_f1\": epoch_f1.item()} # Combine accuracies\n","\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n","                grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # scheduler for one cycle learniing rate\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n","\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","\n","            # gradient clipping\n","            if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            # recording and updating learning rates\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","\n","            # logging to wandb\n","            wandb.log({\"Train Loss\": loss.item()})\n","\n","\n","        # validation\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","\n","        # logging to wandb\n","        wandb.log({\n","            \"Epoch\": epoch,\n","            \"Val Loss\": result['val_loss'],\n","            \"Val Accuracy\": result['val_accuracy'],\n","            \"Val Precision\": result['val_precision'],\n","            \"Val F1\": result['val_f1']\n","        })\n","\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQrurubluIFw"},"outputs":[],"source":["%%time\n","history = fit_one_cycle(\n","  epochs,\n","  max_lr,\n","  model,\n","  train_loader,\n","  val_loader,\n","  grad_clip=grad_clip,\n","  weight_decay=1e-4,\n","  opt_func=opt_func\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MupbAQECSIT"},"outputs":[],"source":["torch.save(model.state_dict(), f'models/plant_disease_aug_alex_{epochs}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLiJ3rNuC04p"},"outputs":[],"source":["# clear nvidia cache\n","import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxqtNO5jNFRTOsdhP5phSM","gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
