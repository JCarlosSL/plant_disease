{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22780,"status":"ok","timestamp":1704829684866,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"9u9_rpVGZc4q","outputId":"94eabe2b-2dcc-4a60-f0fd-ba04af6f8b3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1704829684867,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"Mx1ZAfNva39P","outputId":"ba3bac84-f7f2-444a-f907-5e83a88faec7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/proyectos3\n","alexNet.ipynb  efficientNet.ipynb  models    PlantVillage_bgremoved  wandb\n","cnn.ipynb      GoogleNet.ipynb\t   PlantDoc  resNet.ipynb\n"]}],"source":["%cd /content/drive/MyDrive/proyectos3/\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"QCZO4-Wz9Mi5"},"source":["# Cargar Conjunto de Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13807,"status":"ok","timestamp":1704829698668,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"o2PjUn8wbFMF","outputId":"3415b732-474a-4401-b848-d2afd70f5251"},"outputs":[{"data":{"text/plain":["['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import ConcatDataset\n","\n","\n","train_dir0 = './PlantVillage_bgremoved/train'\n","train_dir1 = './PlantDoc/train/'\n","\n","val_dir0 = './PlantVillage_bgremoved/valid'\n","val_dir1 = './PlantDoc/test/'\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dataset0 = ImageFolder(train_dir0, transform=transform,  is_valid_file=lambda x: x.endswith('.JPG'))\n","train_dataset1 = ImageFolder(train_dir1, transform=transform)\n","\n","val_dataset0 = ImageFolder(val_dir0, transform=transform, is_valid_file=lambda x: x.endswith('.JPG'))\n","val_dataset1 = ImageFolder(val_dir1, transform=transform)\n","\n","train_dataset = ConcatDataset([train_dataset0, train_dataset1])\n","val_dataset = ConcatDataset([val_dataset0, val_dataset1])\n","\n","classes = train_dataset0.classes\n","\n","classes"]},{"cell_type":"markdown","metadata":{"id":"ZugaulR0QBux"},"source":["crear carga de datos para facilitar el acceso a los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rednLcxPyaL"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 32\n","num_workers = 8 # Número de procesos que se utilizarán para cargar datos en paralelo\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSnPPujFQ282"},"outputs":[],"source":["import torch\n","\n","def get_default_device():\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6TcjHtjR0F_"},"outputs":[],"source":["device = get_default_device()\n","\n","train_loader = DeviceDataLoader(train_loader, device)\n","val_loader = DeviceDataLoader(val_loader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704829698669,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"k6XLy8mIIeSy","outputId":"1f1d305a-87e4-4720-f8bb-cab989ce33ab"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWuOy6AJrrnH"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_score, f1_score\n","\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","\n","class ImageClassificationBase(nn.Module):\n","\n","    def training_step(self, batch):\n","        \"calculate loss for a batch of training data\"\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        # nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        \"calculate loss, accuracy, precision and f1 score for a batch of validation data\"\n","        images, labels = batch\n","        out = self(images)                   # Generate prediction\n","        # nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss\n","        loss = F.cross_entropy(out, labels)  # Calculate loss\n","        preds = torch.argmax(out, dim=1)\n","        acc = accuracy(out, labels)          # Calculate accuracy\n","\n","        # calculate precision and f1 score\n","        precision = precision_score(labels.cpu(), preds.cpu(), average='weighted', zero_division=1)\n","        f1 = f1_score(labels.cpu(), preds.cpu(), average='macro')\n","        return {'val_loss': loss.detach(), 'val_accuracy': acc, 'val_precision': precision, 'val_f1': f1}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x[\"val_loss\"] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n","        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n","        epoch_accuracy = torch.stack(batch_accuracy).mean()\n","        return {\"val_loss\": epoch_loss.item(), \"val_accuracy\": epoch_accuracy.item()} # Combine accuracies\n","\n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLTn1g_nsrRn"},"outputs":[],"source":["class EfficientNet(ImageClassificationBase):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.network = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n","        self.network.classifier = nn.Linear(self.network.classifier.in_features, num_classes)\n","\n","    def forward(self, xb):\n","        return self.network(xb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2316,"status":"ok","timestamp":1704829701882,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"EBrx9WYxstKo","outputId":"dfb01330-c636-43fb-8e24-e851a3a13b6c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/rwightman/gen-efficientnet-pytorch/zipball/master\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"]}],"source":["model = EfficientNet(len(classes))\n","model = to_device(model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1224,"status":"ok","timestamp":1704829703098,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"CMuflAwMs0TH","outputId":"057f28fc-f2aa-4904-d7ff-4b4af53c5041"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","              SiLU-3         [-1, 32, 112, 112]               0\n","            Conv2d-4         [-1, 32, 112, 112]             288\n","       BatchNorm2d-5         [-1, 32, 112, 112]              64\n","              SiLU-6         [-1, 32, 112, 112]               0\n","            Conv2d-7              [-1, 8, 1, 1]             264\n","              SiLU-8              [-1, 8, 1, 1]               0\n","            Conv2d-9             [-1, 32, 1, 1]             288\n","    SqueezeExcite-10         [-1, 32, 112, 112]               0\n","           Conv2d-11         [-1, 16, 112, 112]             512\n","      BatchNorm2d-12         [-1, 16, 112, 112]              32\n","         Identity-13         [-1, 16, 112, 112]               0\n","DepthwiseSeparableConv-14         [-1, 16, 112, 112]               0\n","           Conv2d-15         [-1, 96, 112, 112]           1,536\n","      BatchNorm2d-16         [-1, 96, 112, 112]             192\n","             SiLU-17         [-1, 96, 112, 112]               0\n","           Conv2d-18           [-1, 96, 56, 56]             864\n","      BatchNorm2d-19           [-1, 96, 56, 56]             192\n","             SiLU-20           [-1, 96, 56, 56]               0\n","           Conv2d-21              [-1, 4, 1, 1]             388\n","             SiLU-22              [-1, 4, 1, 1]               0\n","           Conv2d-23             [-1, 96, 1, 1]             480\n","    SqueezeExcite-24           [-1, 96, 56, 56]               0\n","           Conv2d-25           [-1, 24, 56, 56]           2,304\n","      BatchNorm2d-26           [-1, 24, 56, 56]              48\n"," InvertedResidual-27           [-1, 24, 56, 56]               0\n","           Conv2d-28          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-29          [-1, 144, 56, 56]             288\n","             SiLU-30          [-1, 144, 56, 56]               0\n","           Conv2d-31          [-1, 144, 56, 56]           1,296\n","      BatchNorm2d-32          [-1, 144, 56, 56]             288\n","             SiLU-33          [-1, 144, 56, 56]               0\n","           Conv2d-34              [-1, 6, 1, 1]             870\n","             SiLU-35              [-1, 6, 1, 1]               0\n","           Conv2d-36            [-1, 144, 1, 1]           1,008\n","    SqueezeExcite-37          [-1, 144, 56, 56]               0\n","           Conv2d-38           [-1, 24, 56, 56]           3,456\n","      BatchNorm2d-39           [-1, 24, 56, 56]              48\n"," InvertedResidual-40           [-1, 24, 56, 56]               0\n","           Conv2d-41          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-42          [-1, 144, 56, 56]             288\n","             SiLU-43          [-1, 144, 56, 56]               0\n","           Conv2d-44          [-1, 144, 28, 28]           3,600\n","      BatchNorm2d-45          [-1, 144, 28, 28]             288\n","             SiLU-46          [-1, 144, 28, 28]               0\n","           Conv2d-47              [-1, 6, 1, 1]             870\n","             SiLU-48              [-1, 6, 1, 1]               0\n","           Conv2d-49            [-1, 144, 1, 1]           1,008\n","    SqueezeExcite-50          [-1, 144, 28, 28]               0\n","           Conv2d-51           [-1, 40, 28, 28]           5,760\n","      BatchNorm2d-52           [-1, 40, 28, 28]              80\n"," InvertedResidual-53           [-1, 40, 28, 28]               0\n","           Conv2d-54          [-1, 240, 28, 28]           9,600\n","      BatchNorm2d-55          [-1, 240, 28, 28]             480\n","             SiLU-56          [-1, 240, 28, 28]               0\n","           Conv2d-57          [-1, 240, 28, 28]           6,000\n","      BatchNorm2d-58          [-1, 240, 28, 28]             480\n","             SiLU-59          [-1, 240, 28, 28]               0\n","           Conv2d-60             [-1, 10, 1, 1]           2,410\n","             SiLU-61             [-1, 10, 1, 1]               0\n","           Conv2d-62            [-1, 240, 1, 1]           2,640\n","    SqueezeExcite-63          [-1, 240, 28, 28]               0\n","           Conv2d-64           [-1, 40, 28, 28]           9,600\n","      BatchNorm2d-65           [-1, 40, 28, 28]              80\n"," InvertedResidual-66           [-1, 40, 28, 28]               0\n","           Conv2d-67          [-1, 240, 28, 28]           9,600\n","      BatchNorm2d-68          [-1, 240, 28, 28]             480\n","             SiLU-69          [-1, 240, 28, 28]               0\n","           Conv2d-70          [-1, 240, 14, 14]           2,160\n","      BatchNorm2d-71          [-1, 240, 14, 14]             480\n","             SiLU-72          [-1, 240, 14, 14]               0\n","           Conv2d-73             [-1, 10, 1, 1]           2,410\n","             SiLU-74             [-1, 10, 1, 1]               0\n","           Conv2d-75            [-1, 240, 1, 1]           2,640\n","    SqueezeExcite-76          [-1, 240, 14, 14]               0\n","           Conv2d-77           [-1, 80, 14, 14]          19,200\n","      BatchNorm2d-78           [-1, 80, 14, 14]             160\n"," InvertedResidual-79           [-1, 80, 14, 14]               0\n","           Conv2d-80          [-1, 480, 14, 14]          38,400\n","      BatchNorm2d-81          [-1, 480, 14, 14]             960\n","             SiLU-82          [-1, 480, 14, 14]               0\n","           Conv2d-83          [-1, 480, 14, 14]           4,320\n","      BatchNorm2d-84          [-1, 480, 14, 14]             960\n","             SiLU-85          [-1, 480, 14, 14]               0\n","           Conv2d-86             [-1, 20, 1, 1]           9,620\n","             SiLU-87             [-1, 20, 1, 1]               0\n","           Conv2d-88            [-1, 480, 1, 1]          10,080\n","    SqueezeExcite-89          [-1, 480, 14, 14]               0\n","           Conv2d-90           [-1, 80, 14, 14]          38,400\n","      BatchNorm2d-91           [-1, 80, 14, 14]             160\n"," InvertedResidual-92           [-1, 80, 14, 14]               0\n","           Conv2d-93          [-1, 480, 14, 14]          38,400\n","      BatchNorm2d-94          [-1, 480, 14, 14]             960\n","             SiLU-95          [-1, 480, 14, 14]               0\n","           Conv2d-96          [-1, 480, 14, 14]           4,320\n","      BatchNorm2d-97          [-1, 480, 14, 14]             960\n","             SiLU-98          [-1, 480, 14, 14]               0\n","           Conv2d-99             [-1, 20, 1, 1]           9,620\n","            SiLU-100             [-1, 20, 1, 1]               0\n","          Conv2d-101            [-1, 480, 1, 1]          10,080\n","   SqueezeExcite-102          [-1, 480, 14, 14]               0\n","          Conv2d-103           [-1, 80, 14, 14]          38,400\n","     BatchNorm2d-104           [-1, 80, 14, 14]             160\n","InvertedResidual-105           [-1, 80, 14, 14]               0\n","          Conv2d-106          [-1, 480, 14, 14]          38,400\n","     BatchNorm2d-107          [-1, 480, 14, 14]             960\n","            SiLU-108          [-1, 480, 14, 14]               0\n","          Conv2d-109          [-1, 480, 14, 14]          12,000\n","     BatchNorm2d-110          [-1, 480, 14, 14]             960\n","            SiLU-111          [-1, 480, 14, 14]               0\n","          Conv2d-112             [-1, 20, 1, 1]           9,620\n","            SiLU-113             [-1, 20, 1, 1]               0\n","          Conv2d-114            [-1, 480, 1, 1]          10,080\n","   SqueezeExcite-115          [-1, 480, 14, 14]               0\n","          Conv2d-116          [-1, 112, 14, 14]          53,760\n","     BatchNorm2d-117          [-1, 112, 14, 14]             224\n","InvertedResidual-118          [-1, 112, 14, 14]               0\n","          Conv2d-119          [-1, 672, 14, 14]          75,264\n","     BatchNorm2d-120          [-1, 672, 14, 14]           1,344\n","            SiLU-121          [-1, 672, 14, 14]               0\n","          Conv2d-122          [-1, 672, 14, 14]          16,800\n","     BatchNorm2d-123          [-1, 672, 14, 14]           1,344\n","            SiLU-124          [-1, 672, 14, 14]               0\n","          Conv2d-125             [-1, 28, 1, 1]          18,844\n","            SiLU-126             [-1, 28, 1, 1]               0\n","          Conv2d-127            [-1, 672, 1, 1]          19,488\n","   SqueezeExcite-128          [-1, 672, 14, 14]               0\n","          Conv2d-129          [-1, 112, 14, 14]          75,264\n","     BatchNorm2d-130          [-1, 112, 14, 14]             224\n","InvertedResidual-131          [-1, 112, 14, 14]               0\n","          Conv2d-132          [-1, 672, 14, 14]          75,264\n","     BatchNorm2d-133          [-1, 672, 14, 14]           1,344\n","            SiLU-134          [-1, 672, 14, 14]               0\n","          Conv2d-135          [-1, 672, 14, 14]          16,800\n","     BatchNorm2d-136          [-1, 672, 14, 14]           1,344\n","            SiLU-137          [-1, 672, 14, 14]               0\n","          Conv2d-138             [-1, 28, 1, 1]          18,844\n","            SiLU-139             [-1, 28, 1, 1]               0\n","          Conv2d-140            [-1, 672, 1, 1]          19,488\n","   SqueezeExcite-141          [-1, 672, 14, 14]               0\n","          Conv2d-142          [-1, 112, 14, 14]          75,264\n","     BatchNorm2d-143          [-1, 112, 14, 14]             224\n","InvertedResidual-144          [-1, 112, 14, 14]               0\n","          Conv2d-145          [-1, 672, 14, 14]          75,264\n","     BatchNorm2d-146          [-1, 672, 14, 14]           1,344\n","            SiLU-147          [-1, 672, 14, 14]               0\n","          Conv2d-148            [-1, 672, 7, 7]          16,800\n","     BatchNorm2d-149            [-1, 672, 7, 7]           1,344\n","            SiLU-150            [-1, 672, 7, 7]               0\n","          Conv2d-151             [-1, 28, 1, 1]          18,844\n","            SiLU-152             [-1, 28, 1, 1]               0\n","          Conv2d-153            [-1, 672, 1, 1]          19,488\n","   SqueezeExcite-154            [-1, 672, 7, 7]               0\n","          Conv2d-155            [-1, 192, 7, 7]         129,024\n","     BatchNorm2d-156            [-1, 192, 7, 7]             384\n","InvertedResidual-157            [-1, 192, 7, 7]               0\n","          Conv2d-158           [-1, 1152, 7, 7]         221,184\n","     BatchNorm2d-159           [-1, 1152, 7, 7]           2,304\n","            SiLU-160           [-1, 1152, 7, 7]               0\n","          Conv2d-161           [-1, 1152, 7, 7]          28,800\n","     BatchNorm2d-162           [-1, 1152, 7, 7]           2,304\n","            SiLU-163           [-1, 1152, 7, 7]               0\n","          Conv2d-164             [-1, 48, 1, 1]          55,344\n","            SiLU-165             [-1, 48, 1, 1]               0\n","          Conv2d-166           [-1, 1152, 1, 1]          56,448\n","   SqueezeExcite-167           [-1, 1152, 7, 7]               0\n","          Conv2d-168            [-1, 192, 7, 7]         221,184\n","     BatchNorm2d-169            [-1, 192, 7, 7]             384\n","InvertedResidual-170            [-1, 192, 7, 7]               0\n","          Conv2d-171           [-1, 1152, 7, 7]         221,184\n","     BatchNorm2d-172           [-1, 1152, 7, 7]           2,304\n","            SiLU-173           [-1, 1152, 7, 7]               0\n","          Conv2d-174           [-1, 1152, 7, 7]          28,800\n","     BatchNorm2d-175           [-1, 1152, 7, 7]           2,304\n","            SiLU-176           [-1, 1152, 7, 7]               0\n","          Conv2d-177             [-1, 48, 1, 1]          55,344\n","            SiLU-178             [-1, 48, 1, 1]               0\n","          Conv2d-179           [-1, 1152, 1, 1]          56,448\n","   SqueezeExcite-180           [-1, 1152, 7, 7]               0\n","          Conv2d-181            [-1, 192, 7, 7]         221,184\n","     BatchNorm2d-182            [-1, 192, 7, 7]             384\n","InvertedResidual-183            [-1, 192, 7, 7]               0\n","          Conv2d-184           [-1, 1152, 7, 7]         221,184\n","     BatchNorm2d-185           [-1, 1152, 7, 7]           2,304\n","            SiLU-186           [-1, 1152, 7, 7]               0\n","          Conv2d-187           [-1, 1152, 7, 7]          28,800\n","     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n","            SiLU-189           [-1, 1152, 7, 7]               0\n","          Conv2d-190             [-1, 48, 1, 1]          55,344\n","            SiLU-191             [-1, 48, 1, 1]               0\n","          Conv2d-192           [-1, 1152, 1, 1]          56,448\n","   SqueezeExcite-193           [-1, 1152, 7, 7]               0\n","          Conv2d-194            [-1, 192, 7, 7]         221,184\n","     BatchNorm2d-195            [-1, 192, 7, 7]             384\n","InvertedResidual-196            [-1, 192, 7, 7]               0\n","          Conv2d-197           [-1, 1152, 7, 7]         221,184\n","     BatchNorm2d-198           [-1, 1152, 7, 7]           2,304\n","            SiLU-199           [-1, 1152, 7, 7]               0\n","          Conv2d-200           [-1, 1152, 7, 7]          10,368\n","     BatchNorm2d-201           [-1, 1152, 7, 7]           2,304\n","            SiLU-202           [-1, 1152, 7, 7]               0\n","          Conv2d-203             [-1, 48, 1, 1]          55,344\n","            SiLU-204             [-1, 48, 1, 1]               0\n","          Conv2d-205           [-1, 1152, 1, 1]          56,448\n","   SqueezeExcite-206           [-1, 1152, 7, 7]               0\n","          Conv2d-207            [-1, 320, 7, 7]         368,640\n","     BatchNorm2d-208            [-1, 320, 7, 7]             640\n","InvertedResidual-209            [-1, 320, 7, 7]               0\n","          Conv2d-210           [-1, 1280, 7, 7]         409,600\n","     BatchNorm2d-211           [-1, 1280, 7, 7]           2,560\n","            SiLU-212           [-1, 1280, 7, 7]               0\n","AdaptiveAvgPool2d-213           [-1, 1280, 1, 1]               0\n","          Linear-214                    [-1, 3]           3,843\n"," GenEfficientNet-215                    [-1, 3]               0\n","================================================================\n","Total params: 4,011,391\n","Trainable params: 4,011,391\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 173.43\n","Params size (MB): 15.30\n","Estimated Total Size (MB): 189.30\n","----------------------------------------------------------------\n","None\n"]}],"source":["from torchsummary import summary              # for getting the summary of our model\n","\n","# getting summary of the model\n","INPUT_SHAPE = (3, 224, 224)\n","print(summary(model.cuda(), (INPUT_SHAPE)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z270ebzHs1Gf"},"outputs":[],"source":["epochs = 100\n","\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8897,"status":"ok","timestamp":1704829711988,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"ayepRCIt_yZL","outputId":"ba071f1b-b1bb-4220-9ac8-daefce3eac1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704829711988,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"L7oieSf5s5LY","outputId":"4cae5c60-a8c2-4a2e-a8f2-9facf9e6681e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nimport wandb\\n\\nname = f\\'efficientNet-{epochs}-epochs\\'\\nwandb.init(project=\"plantvillage-aug\", name=name, config={\\n    \"epochs\": epochs,\\n    \"learning_rate\": max_lr,\\n    \"grad_clip\": grad_clip,\\n    \"weight_decay\": weight_decay,\\n    \"opt_func\": opt_func.__name__,\\n    \"batch_size\": batch_size,\\n    \"dataset\": \"PlantVillage\",\\n    \"architecture\": \"efficientNet\"\\n})\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\n","import wandb\n","\n","name = f'efficientNet-{epochs}-epochs'\n","wandb.init(project=\"plantvillage-aug\", name=name, config={\n","    \"epochs\": epochs,\n","    \"learning_rate\": max_lr,\n","    \"grad_clip\": grad_clip,\n","    \"weight_decay\": weight_decay,\n","    \"opt_func\": opt_func.__name__,\n","    \"batch_size\": batch_size,\n","    \"dataset\": \"PlantVillage\",\n","    \"architecture\": \"efficientNet\"\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtS2oLwuuAx5"},"outputs":[],"source":["# for training\n","@torch.no_grad()\n","def evaluate(model, val_loader):\n","    \"\"\"Evaluates the model's performance on the validation set\"\"\"\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    # return model.validation_epoch_end(outputs)\n","    val_losses = [x[\"val_loss\"] for x in outputs]\n","    epoch_loss = torch.stack(val_losses).mean()       # Combine loss\n","    val_accuracies = [x[\"val_accuracy\"] for x in outputs]\n","    epoch_accuracy = torch.stack(val_accuracies).mean()\n","    val_precisions = [x[\"val_precision\"] for x in outputs]\n","    epoch_precision = torch.tensor(sum(val_precisions)/len(val_precisions))\n","    val_f1s = [x[\"val_f1\"] for x in outputs]\n","    epoch_f1 = torch.tensor(sum(val_f1s)/len(val_f1s))\n","    return {\"val_loss\": epoch_loss.item(), \"val_accuracy\": epoch_accuracy.item(), \"val_precision\": epoch_precision.item(), \"val_f1\": epoch_f1.item()} # Combine accuracies\n","\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n","                grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # scheduler for one cycle learniing rate\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n","\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","\n","            # gradient clipping\n","            if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            # recording and updating learning rates\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","\n","            # logging to wandb\n","            # wandb.log({\"Train Loss\": loss.item()})\n","\n","\n","        # validation\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","\n","        # logging to wandb\n","        wandb.log({\n","            \"Epoch\": epoch,\n","            \"Val Loss\": result['val_loss'],\n","            \"Val Accuracy\": result['val_accuracy'],\n","            \"Val Precision\": result['val_precision'],\n","            \"Val F1\": result['val_f1']\n","        })\n","\n","    return history"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1797333,"status":"ok","timestamp":1704833016659,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"wQrurubluIFw","outputId":"e18f4e00-6650-41a6-dc28-e1d759ef1965"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0], last_lr: 0.00043, train_loss: 0.2199, val_loss: 0.2648, val_acc: 0.9145\n","Epoch [1], last_lr: 0.00050, train_loss: 0.0724, val_loss: 0.0627, val_acc: 0.9803\n","Epoch [2], last_lr: 0.00063, train_loss: 0.0517, val_loss: 0.1350, val_acc: 0.9227\n","Epoch [3], last_lr: 0.00081, train_loss: 0.0612, val_loss: 0.3224, val_acc: 0.9062\n","Epoch [4], last_lr: 0.00104, train_loss: 0.0698, val_loss: 1.1520, val_acc: 0.9786\n","Epoch [5], last_lr: 0.00131, train_loss: 0.0842, val_loss: 0.0985, val_acc: 0.9720\n","Epoch [6], last_lr: 0.00163, train_loss: 0.0818, val_loss: 0.1726, val_acc: 0.9688\n","Epoch [7], last_lr: 0.00198, train_loss: 0.0884, val_loss: 0.1558, val_acc: 0.9441\n","Epoch [8], last_lr: 0.00237, train_loss: 0.1730, val_loss: 0.0662, val_acc: 0.9770\n","Epoch [9], last_lr: 0.00280, train_loss: 0.1016, val_loss: 0.3949, val_acc: 0.9243\n","Epoch [10], last_lr: 0.00324, train_loss: 0.0812, val_loss: 0.0671, val_acc: 0.9786\n","Epoch [11], last_lr: 0.00371, train_loss: 0.0960, val_loss: 0.2683, val_acc: 0.9523\n","Epoch [12], last_lr: 0.00420, train_loss: 0.1840, val_loss: 0.3163, val_acc: 0.8701\n","Epoch [13], last_lr: 0.00469, train_loss: 0.1182, val_loss: 0.1864, val_acc: 0.9243\n","Epoch [14], last_lr: 0.00520, train_loss: 0.0812, val_loss: 0.1825, val_acc: 0.9424\n","Epoch [15], last_lr: 0.00570, train_loss: 0.1597, val_loss: 0.0904, val_acc: 0.9720\n","Epoch [16], last_lr: 0.00620, train_loss: 0.1254, val_loss: 0.4270, val_acc: 0.8207\n","Epoch [17], last_lr: 0.00668, train_loss: 0.1187, val_loss: 0.4125, val_acc: 0.9178\n","Epoch [18], last_lr: 0.00715, train_loss: 0.1348, val_loss: 0.4775, val_acc: 0.8750\n","Epoch [19], last_lr: 0.00760, train_loss: 0.1217, val_loss: 0.3905, val_acc: 0.8734\n","Epoch [20], last_lr: 0.00802, train_loss: 0.1098, val_loss: 0.5408, val_acc: 0.8092\n","Epoch [21], last_lr: 0.00841, train_loss: 0.2357, val_loss: 0.1599, val_acc: 0.9474\n","Epoch [22], last_lr: 0.00877, train_loss: 0.1224, val_loss: 0.3487, val_acc: 0.8586\n","Epoch [23], last_lr: 0.00908, train_loss: 0.1288, val_loss: 0.5494, val_acc: 0.8059\n","Epoch [24], last_lr: 0.00936, train_loss: 0.0993, val_loss: 0.7129, val_acc: 0.8158\n","Epoch [25], last_lr: 0.00958, train_loss: 0.1250, val_loss: 0.0763, val_acc: 0.9720\n","Epoch [26], last_lr: 0.00976, train_loss: 0.1081, val_loss: 0.1709, val_acc: 0.9622\n","Epoch [27], last_lr: 0.00990, train_loss: 0.1072, val_loss: 0.2241, val_acc: 0.8964\n","Epoch [28], last_lr: 0.00997, train_loss: 0.0978, val_loss: 0.1689, val_acc: 0.9424\n","Epoch [29], last_lr: 0.01000, train_loss: 0.1576, val_loss: 0.4923, val_acc: 0.7911\n","Epoch [30], last_lr: 0.00999, train_loss: 0.1193, val_loss: 0.4149, val_acc: 0.8684\n","Epoch [31], last_lr: 0.00998, train_loss: 0.1082, val_loss: 0.0926, val_acc: 0.9737\n","Epoch [32], last_lr: 0.00995, train_loss: 0.0884, val_loss: 0.0955, val_acc: 0.9704\n","Epoch [33], last_lr: 0.00992, train_loss: 0.0819, val_loss: 0.2633, val_acc: 0.9359\n","Epoch [34], last_lr: 0.00987, train_loss: 0.0740, val_loss: 0.2722, val_acc: 0.9079\n","Epoch [35], last_lr: 0.00982, train_loss: 0.0887, val_loss: 0.3925, val_acc: 0.8849\n","Epoch [36], last_lr: 0.00976, train_loss: 0.1080, val_loss: 0.1307, val_acc: 0.9655\n","Epoch [37], last_lr: 0.00968, train_loss: 0.1010, val_loss: 0.4684, val_acc: 0.8454\n","Epoch [38], last_lr: 0.00960, train_loss: 0.0746, val_loss: 0.1312, val_acc: 0.9655\n","Epoch [39], last_lr: 0.00950, train_loss: 0.0706, val_loss: 0.1258, val_acc: 0.9589\n","Epoch [40], last_lr: 0.00940, train_loss: 0.0728, val_loss: 0.2151, val_acc: 0.9375\n","Epoch [41], last_lr: 0.00929, train_loss: 0.0768, val_loss: 1.0924, val_acc: 0.6184\n","Epoch [42], last_lr: 0.00917, train_loss: 0.1069, val_loss: 0.1851, val_acc: 0.9572\n","Epoch [43], last_lr: 0.00905, train_loss: 0.0709, val_loss: 0.3407, val_acc: 0.9474\n","Epoch [44], last_lr: 0.00891, train_loss: 0.0632, val_loss: 2.0239, val_acc: 0.4523\n","Epoch [45], last_lr: 0.00877, train_loss: 0.0757, val_loss: 0.1660, val_acc: 0.9523\n","Epoch [46], last_lr: 0.00861, train_loss: 0.0571, val_loss: 0.1272, val_acc: 0.9539\n","Epoch [47], last_lr: 0.00846, train_loss: 0.0840, val_loss: 0.1324, val_acc: 0.9720\n","Epoch [48], last_lr: 0.00829, train_loss: 0.0561, val_loss: 0.1427, val_acc: 0.9194\n","Epoch [49], last_lr: 0.00812, train_loss: 0.0665, val_loss: 0.3211, val_acc: 0.8750\n","Epoch [50], last_lr: 0.00794, train_loss: 0.0411, val_loss: 0.6172, val_acc: 0.8536\n","Epoch [51], last_lr: 0.00775, train_loss: 0.0925, val_loss: 0.3034, val_acc: 0.8882\n","Epoch [52], last_lr: 0.00756, train_loss: 0.0761, val_loss: 0.2380, val_acc: 0.9112\n","Epoch [53], last_lr: 0.00737, train_loss: 0.0470, val_loss: 0.2847, val_acc: 0.9260\n","Epoch [54], last_lr: 0.00717, train_loss: 0.0559, val_loss: 0.0950, val_acc: 0.9753\n","Epoch [55], last_lr: 0.00697, train_loss: 0.0472, val_loss: 0.1737, val_acc: 0.9622\n","Epoch [56], last_lr: 0.00676, train_loss: 0.0801, val_loss: 0.1510, val_acc: 0.9474\n","Epoch [57], last_lr: 0.00655, train_loss: 0.0515, val_loss: 0.2489, val_acc: 0.8898\n","Epoch [58], last_lr: 0.00633, train_loss: 0.0333, val_loss: 0.1642, val_acc: 0.9589\n","Epoch [59], last_lr: 0.00611, train_loss: 0.0235, val_loss: 0.2934, val_acc: 0.9572\n","Epoch [60], last_lr: 0.00589, train_loss: 0.0544, val_loss: 0.1942, val_acc: 0.9688\n","Epoch [61], last_lr: 0.00567, train_loss: 0.0301, val_loss: 0.2901, val_acc: 0.8832\n","Epoch [62], last_lr: 0.00545, train_loss: 0.0260, val_loss: 0.1889, val_acc: 0.9309\n","Epoch [63], last_lr: 0.00522, train_loss: 0.0259, val_loss: 0.2171, val_acc: 0.9605\n","Epoch [64], last_lr: 0.00500, train_loss: 0.0317, val_loss: 0.1206, val_acc: 0.9572\n","Epoch [65], last_lr: 0.00478, train_loss: 0.0386, val_loss: 0.1422, val_acc: 0.9671\n","Epoch [66], last_lr: 0.00455, train_loss: 0.0273, val_loss: 0.1363, val_acc: 0.9704\n","Epoch [67], last_lr: 0.00433, train_loss: 0.0182, val_loss: 0.2111, val_acc: 0.9605\n","Epoch [68], last_lr: 0.00411, train_loss: 0.0141, val_loss: 0.1633, val_acc: 0.9655\n","Epoch [69], last_lr: 0.00389, train_loss: 0.0164, val_loss: 0.1391, val_acc: 0.9671\n","Epoch [70], last_lr: 0.00367, train_loss: 0.0095, val_loss: 0.1908, val_acc: 0.9161\n","Epoch [71], last_lr: 0.00345, train_loss: 0.0102, val_loss: 0.1218, val_acc: 0.9688\n","Epoch [72], last_lr: 0.00324, train_loss: 0.0104, val_loss: 0.1305, val_acc: 0.9671\n","Epoch [73], last_lr: 0.00303, train_loss: 0.0061, val_loss: 0.1595, val_acc: 0.9671\n","Epoch [74], last_lr: 0.00283, train_loss: 0.0090, val_loss: 0.1638, val_acc: 0.9638\n","Epoch [75], last_lr: 0.00263, train_loss: 0.0072, val_loss: 0.1661, val_acc: 0.9704\n","Epoch [76], last_lr: 0.00244, train_loss: 0.0025, val_loss: 0.2141, val_acc: 0.9161\n","Epoch [77], last_lr: 0.00225, train_loss: 0.0044, val_loss: 0.2377, val_acc: 0.9079\n","Epoch [78], last_lr: 0.00206, train_loss: 0.0052, val_loss: 0.2080, val_acc: 0.9145\n","Epoch [79], last_lr: 0.00188, train_loss: 0.0040, val_loss: 0.1707, val_acc: 0.9638\n","Epoch [80], last_lr: 0.00171, train_loss: 0.0032, val_loss: 0.1614, val_acc: 0.9688\n","Epoch [81], last_lr: 0.00154, train_loss: 0.0022, val_loss: 0.1566, val_acc: 0.9671\n","Epoch [82], last_lr: 0.00139, train_loss: 0.0059, val_loss: 0.1774, val_acc: 0.9622\n","Epoch [83], last_lr: 0.00123, train_loss: 0.0033, val_loss: 0.1696, val_acc: 0.9605\n","Epoch [84], last_lr: 0.00109, train_loss: 0.0020, val_loss: 0.1535, val_acc: 0.9655\n","Epoch [85], last_lr: 0.00095, train_loss: 0.0025, val_loss: 0.1500, val_acc: 0.9688\n","Epoch [86], last_lr: 0.00083, train_loss: 0.0014, val_loss: 0.1716, val_acc: 0.9638\n","Epoch [87], last_lr: 0.00071, train_loss: 0.0021, val_loss: 0.1676, val_acc: 0.9655\n","Epoch [88], last_lr: 0.00060, train_loss: 0.0051, val_loss: 0.1662, val_acc: 0.9655\n","Epoch [89], last_lr: 0.00050, train_loss: 0.0019, val_loss: 0.1717, val_acc: 0.9671\n","Epoch [90], last_lr: 0.00040, train_loss: 0.0016, val_loss: 0.1758, val_acc: 0.9655\n","Epoch [91], last_lr: 0.00032, train_loss: 0.0018, val_loss: 0.1812, val_acc: 0.9622\n","Epoch [92], last_lr: 0.00024, train_loss: 0.0014, val_loss: 0.1743, val_acc: 0.9655\n","Epoch [93], last_lr: 0.00018, train_loss: 0.0023, val_loss: 0.1861, val_acc: 0.9622\n","Epoch [94], last_lr: 0.00013, train_loss: 0.0016, val_loss: 0.1970, val_acc: 0.9605\n","Epoch [95], last_lr: 0.00008, train_loss: 0.0016, val_loss: 0.1858, val_acc: 0.9622\n","Epoch [96], last_lr: 0.00005, train_loss: 0.0019, val_loss: 0.1836, val_acc: 0.9622\n","Epoch [97], last_lr: 0.00002, train_loss: 0.0021, val_loss: 0.1638, val_acc: 0.9655\n","Epoch [98], last_lr: 0.00001, train_loss: 0.0016, val_loss: 0.1836, val_acc: 0.9671\n","Epoch [99], last_lr: 0.00000, train_loss: 0.0014, val_loss: 0.1709, val_acc: 0.9655\n","CPU times: user 32min 1s, sys: 59.9 s, total: 33min 1s\n","Wall time: 55min 4s\n"]}],"source":["%%time\n","history = fit_one_cycle(\n","  epochs,\n","  max_lr,\n","  model,\n","  train_loader,\n","  val_loader,\n","  grad_clip=grad_clip,\n","  weight_decay=1e-4,\n","  opt_func=opt_func\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704833016660,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"4Vk7vsnUhstP"},"outputs":[],"source":["torch.save(model.state_dict(), f'models/plant_disease_aug_efficientNet_{epochs}.pth')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1704833016958,"user":{"displayName":"Jean Carlos Soncco Lupa","userId":"15843525091642984262"},"user_tz":300},"id":"cLiJ3rNuC04p"},"outputs":[],"source":["# clear nvidia cache\n","import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPTHt20mqmfQ8HNZ4bgWGnL","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
